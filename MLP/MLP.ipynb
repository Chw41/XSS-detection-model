{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T10:37:30.192718Z",
     "iopub.status.busy": "2024-12-24T10:37:30.192560Z",
     "iopub.status.idle": "2024-12-24T10:37:31.524166Z",
     "shell.execute_reply": "2024-12-24T10:37:31.523781Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T10:37:31.525915Z",
     "iopub.status.busy": "2024-12-24T10:37:31.525717Z",
     "iopub.status.idle": "2024-12-24T10:37:31.528463Z",
     "shell.execute_reply": "2024-12-24T10:37:31.528155Z"
    }
   },
   "outputs": [],
   "source": [
    "class XSSDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T10:37:31.529702Z",
     "iopub.status.busy": "2024-12-24T10:37:31.529575Z",
     "iopub.status.idle": "2024-12-24T10:37:31.536433Z",
     "shell.execute_reply": "2024-12-24T10:37:31.536166Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, optimizer, criterion, total_epochs):\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 5\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in range(total_epochs):\n",
    "        model.train()\n",
    "        train_epoch_loss = 0\n",
    "        for features, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_epoch_loss += loss.item()\n",
    "        \n",
    "        train_epoch_loss /= len(train_loader)\n",
    "        train_losses.append(train_epoch_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        val_epoch_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_epoch_loss += loss.item()\n",
    "            \n",
    "            val_epoch_loss /= len(val_loader)\n",
    "            val_losses.append(val_epoch_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{total_epochs}: Train Loss = {train_epoch_loss:.4f}, Val Loss = {val_epoch_loss:.4f}')\n",
    "        \n",
    "        # Early stopping logic, but only after min 10 epochs\n",
    "        if epoch >= 50:\n",
    "            if val_epoch_loss < best_val_loss:\n",
    "                best_val_loss = val_epoch_loss\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "            \n",
    "            if counter >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "    \n",
    "    # Ensure we always have total_epochs data points for plotting\n",
    "    while len(train_losses) < total_epochs:\n",
    "        train_losses.append(train_losses[-1])\n",
    "        val_losses.append(val_losses[-1])\n",
    "    \n",
    "    return train_losses[:total_epochs], val_losses[:total_epochs]\n",
    "\n",
    "def evaluate_metrics(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            outputs = model(features)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'F1 Score': f1,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "    }\n",
    "\n",
    "def plot_loss_curves(learning_rates, all_train_losses, all_val_losses, total_epochs):\n",
    "    # 1. Individual plots with x-axis ticks every 5 epochs\n",
    "    for lr, train_losses, val_losses in zip(learning_rates, all_train_losses, all_val_losses):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        epochs = range(1, len(train_losses) + 1)\n",
    "        plt.plot(epochs, train_losses, label='Train Loss', marker='o')\n",
    "        plt.plot(epochs, val_losses, label='Validation Loss', marker='o')\n",
    "        plt.title(f'Loss Curves - Learning Rate: {lr}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Set x-axis ticks every 5 epochs\n",
    "        plt.xticks(range(0, total_epochs + 1, 5))\n",
    "        plt.ylim(bottom=0)\n",
    "        \n",
    "        # Save individual plot\n",
    "        plt.savefig(f'MLP_loss_plot_lr_{lr}.png')\n",
    "        plt.close()\n",
    "\n",
    "    # 2. Combined training losses plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for lr, train_losses in zip(learning_rates, all_train_losses):\n",
    "        plt.plot(range(1, len(train_losses) + 1), train_losses, \n",
    "                label=f'LR = {lr}', marker='o', markersize=4)\n",
    "    \n",
    "    plt.title('Training Loss Comparison Across Learning Rates')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(range(0, total_epochs + 1, 5))\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.savefig('MLP_combined_training_losses.png')\n",
    "    plt.close()\n",
    "\n",
    "    # 3. Combined validation losses plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for lr, val_losses in zip(learning_rates, all_val_losses):\n",
    "        plt.plot(range(1, len(val_losses) + 1), val_losses, \n",
    "                label=f'LR = {lr}', marker='o', markersize=4)\n",
    "    \n",
    "    plt.title('Validation Loss Comparison Across Learning Rates')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(range(0, total_epochs + 1, 5))\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.savefig('MLP_combined_validation_losses.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T10:37:31.537666Z",
     "iopub.status.busy": "2024-12-24T10:37:31.537519Z",
     "iopub.status.idle": "2024-12-24T10:37:31.541501Z",
     "shell.execute_reply": "2024-12-24T10:37:31.541248Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Load dataset\n",
    "    dataset_path = '../Training Dataset/final_dataset.csv'\n",
    "    \n",
    "    # Read CSV and handle NaN values\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    \n",
    "    # Remove rows with NaN values in 'Sentence' or 'Label' columns\n",
    "    df = df.dropna(subset=['Sentence', 'Label'])\n",
    "    \n",
    "    # Convert 'Sentence' to string type and replace any remaining NaNs\n",
    "    df['Sentence'] = df['Sentence'].astype(str).fillna('')\n",
    "    \n",
    "    # Print dataset info\n",
    "    print(\"Dataset shape after cleaning:\", df.shape)\n",
    "    print(\"\\nSample of cleaned dataset:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Text Vectorization\n",
    "    vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    X = vectorizer.fit_transform(df['Sentence']).toarray()\n",
    "    y = df['Label'].values\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.33, random_state=42)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataset = XSSDataset(X_train, y_train)\n",
    "    val_dataset = XSSDataset(X_val, y_val)\n",
    "    test_dataset = XSSDataset(X_test, y_test)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "    \n",
    "    # Print first 3 samples\n",
    "    print(\"\\nFirst 3 Training Samples:\")\n",
    "    for i, (features, label) in enumerate(train_loader):\n",
    "        if i < 1:\n",
    "            print(\"Features shape:\", features[:3].shape)\n",
    "            print(\"Labels:\", label[:3])\n",
    "        break\n",
    "    \n",
    "    # Learning rates to experiment\n",
    "    learning_rates = [0.001, 0.002, 0.01, 0.02, 0.05]\n",
    "    total_epochs = 50\n",
    "    results = {}\n",
    "    \n",
    "    all_train_losses = []\n",
    "    all_val_losses = []\n",
    "    \n",
    "    for lr in learning_rates:\n",
    "        print(f\"\\n--- Learning Rate: {lr} ---\")\n",
    "        \n",
    "        model = MLPModel(X_train.shape[1])\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Train and evaluate\n",
    "        train_losses, val_losses = train_and_evaluate(\n",
    "            model, train_loader, val_loader, optimizer, criterion, total_epochs\n",
    "        )\n",
    "        \n",
    "        # Store losses for later plotting\n",
    "        all_train_losses.append(train_losses)\n",
    "        all_val_losses.append(val_losses)\n",
    "        \n",
    "        # Save model weights\n",
    "        model_path = f'MLP_model_lr_{lr}.pth'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "        # Evaluate metrics\n",
    "        metrics = evaluate_metrics(model, test_loader)\n",
    "        results[lr] = metrics\n",
    "        print(\"Metrics:\", metrics)\n",
    "    \n",
    "    # Plot all loss curves\n",
    "    plot_loss_curves(learning_rates, all_train_losses, all_val_losses, total_epochs)\n",
    "    \n",
    "    # Print comprehensive results\n",
    "    print(\"\\n--- Comprehensive Results ---\")\n",
    "    for lr, metrics in results.items():\n",
    "        print(f\"\\nLearning Rate: {lr}\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T10:37:31.542691Z",
     "iopub.status.busy": "2024-12-24T10:37:31.542518Z",
     "iopub.status.idle": "2024-12-24T10:47:41.820000Z",
     "shell.execute_reply": "2024-12-24T10:47:41.819670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after cleaning: (88309, 3)\n",
      "\n",
      "Sample of cleaned dataset:\n",
      "   Unnamed: 0                                           Sentence  Label\n",
      "0           0  form.search_text=Dell%22%3E%3Cscript%3Ealert(/...      1\n",
      "1           1         site=message&msg=<script>alert(1)</script>      1\n",
      "2           2  Itemid=%22onmouseover=alert%28document.cookie%...      1\n",
      "3           3  uilang=en%22%3E%3Cscript%3Ealert%28document.co...      1\n",
      "4           4  msg=<ScRiPt>alert('LastRider-CyberBellona')</S...      1\n",
      "\n",
      "First 3 Training Samples:\n",
      "Features shape: torch.Size([3, 1000])\n",
      "Labels: tensor([1, 1, 0])\n",
      "\n",
      "--- Learning Rate: 0.001 ---\n",
      "Epoch 1/50: Train Loss = 0.0631, Val Loss = 0.0260\n",
      "Epoch 2/50: Train Loss = 0.0283, Val Loss = 0.0257\n",
      "Epoch 3/50: Train Loss = 0.0268, Val Loss = 0.0260\n",
      "Epoch 4/50: Train Loss = 0.0249, Val Loss = 0.0251\n",
      "Epoch 5/50: Train Loss = 0.0237, Val Loss = 0.0254\n",
      "Epoch 6/50: Train Loss = 0.0235, Val Loss = 0.0256\n",
      "Epoch 7/50: Train Loss = 0.0228, Val Loss = 0.0275\n",
      "Epoch 8/50: Train Loss = 0.0221, Val Loss = 0.0270\n",
      "Epoch 9/50: Train Loss = 0.0224, Val Loss = 0.0273\n",
      "Epoch 10/50: Train Loss = 0.0220, Val Loss = 0.0280\n",
      "Epoch 11/50: Train Loss = 0.0215, Val Loss = 0.0274\n",
      "Epoch 12/50: Train Loss = 0.0214, Val Loss = 0.0291\n",
      "Epoch 13/50: Train Loss = 0.0208, Val Loss = 0.0280\n",
      "Epoch 14/50: Train Loss = 0.0211, Val Loss = 0.0287\n",
      "Epoch 15/50: Train Loss = 0.0207, Val Loss = 0.0304\n",
      "Epoch 16/50: Train Loss = 0.0207, Val Loss = 0.0297\n",
      "Epoch 17/50: Train Loss = 0.0205, Val Loss = 0.0302\n",
      "Epoch 18/50: Train Loss = 0.0201, Val Loss = 0.0313\n",
      "Epoch 19/50: Train Loss = 0.0200, Val Loss = 0.0321\n",
      "Epoch 20/50: Train Loss = 0.0200, Val Loss = 0.0321\n",
      "Epoch 21/50: Train Loss = 0.0201, Val Loss = 0.0317\n",
      "Epoch 22/50: Train Loss = 0.0197, Val Loss = 0.0317\n",
      "Epoch 23/50: Train Loss = 0.0197, Val Loss = 0.0318\n",
      "Epoch 24/50: Train Loss = 0.0196, Val Loss = 0.0315\n",
      "Epoch 25/50: Train Loss = 0.0194, Val Loss = 0.0346\n",
      "Epoch 26/50: Train Loss = 0.0192, Val Loss = 0.0338\n",
      "Epoch 27/50: Train Loss = 0.0193, Val Loss = 0.0319\n",
      "Epoch 28/50: Train Loss = 0.0194, Val Loss = 0.0329\n",
      "Epoch 29/50: Train Loss = 0.0190, Val Loss = 0.0352\n",
      "Epoch 30/50: Train Loss = 0.0189, Val Loss = 0.0340\n",
      "Epoch 31/50: Train Loss = 0.0191, Val Loss = 0.0348\n",
      "Epoch 32/50: Train Loss = 0.0191, Val Loss = 0.0356\n",
      "Epoch 33/50: Train Loss = 0.0190, Val Loss = 0.0358\n",
      "Epoch 34/50: Train Loss = 0.0189, Val Loss = 0.0355\n",
      "Epoch 35/50: Train Loss = 0.0188, Val Loss = 0.0362\n",
      "Epoch 36/50: Train Loss = 0.0188, Val Loss = 0.0376\n",
      "Epoch 37/50: Train Loss = 0.0189, Val Loss = 0.0351\n",
      "Epoch 38/50: Train Loss = 0.0187, Val Loss = 0.0357\n",
      "Epoch 39/50: Train Loss = 0.0186, Val Loss = 0.0368\n",
      "Epoch 40/50: Train Loss = 0.0189, Val Loss = 0.0351\n",
      "Epoch 41/50: Train Loss = 0.0187, Val Loss = 0.0375\n",
      "Epoch 42/50: Train Loss = 0.0185, Val Loss = 0.0395\n",
      "Epoch 43/50: Train Loss = 0.0188, Val Loss = 0.0357\n",
      "Epoch 44/50: Train Loss = 0.0187, Val Loss = 0.0378\n",
      "Epoch 45/50: Train Loss = 0.0186, Val Loss = 0.0381\n",
      "Epoch 46/50: Train Loss = 0.0189, Val Loss = 0.0380\n",
      "Epoch 47/50: Train Loss = 0.0185, Val Loss = 0.0362\n",
      "Epoch 48/50: Train Loss = 0.0185, Val Loss = 0.0389\n",
      "Epoch 49/50: Train Loss = 0.0184, Val Loss = 0.0388\n",
      "Epoch 50/50: Train Loss = 0.0184, Val Loss = 0.0394\n",
      "Metrics: {'F1 Score': 0.9926834152594892, 'Accuracy': 0.9926798581722521, 'Precision': 0.9927139965667622, 'Recall': 0.9926798581722521}\n",
      "\n",
      "--- Learning Rate: 0.002 ---\n",
      "Epoch 1/50: Train Loss = 0.0498, Val Loss = 0.0270\n",
      "Epoch 2/50: Train Loss = 0.0280, Val Loss = 0.0256\n",
      "Epoch 3/50: Train Loss = 0.0257, Val Loss = 0.0271\n",
      "Epoch 4/50: Train Loss = 0.0244, Val Loss = 0.0259\n",
      "Epoch 5/50: Train Loss = 0.0236, Val Loss = 0.0266\n",
      "Epoch 6/50: Train Loss = 0.0227, Val Loss = 0.0286\n",
      "Epoch 7/50: Train Loss = 0.0226, Val Loss = 0.0266\n",
      "Epoch 8/50: Train Loss = 0.0221, Val Loss = 0.0285\n",
      "Epoch 9/50: Train Loss = 0.0217, Val Loss = 0.0298\n",
      "Epoch 10/50: Train Loss = 0.0215, Val Loss = 0.0285\n",
      "Epoch 11/50: Train Loss = 0.0213, Val Loss = 0.0302\n",
      "Epoch 12/50: Train Loss = 0.0207, Val Loss = 0.0302\n",
      "Epoch 13/50: Train Loss = 0.0204, Val Loss = 0.0307\n",
      "Epoch 14/50: Train Loss = 0.0205, Val Loss = 0.0306\n",
      "Epoch 15/50: Train Loss = 0.0200, Val Loss = 0.0319\n",
      "Epoch 16/50: Train Loss = 0.0198, Val Loss = 0.0308\n",
      "Epoch 17/50: Train Loss = 0.0198, Val Loss = 0.0353\n",
      "Epoch 18/50: Train Loss = 0.0196, Val Loss = 0.0323\n",
      "Epoch 19/50: Train Loss = 0.0196, Val Loss = 0.0350\n",
      "Epoch 20/50: Train Loss = 0.0195, Val Loss = 0.0327\n",
      "Epoch 21/50: Train Loss = 0.0198, Val Loss = 0.0354\n",
      "Epoch 22/50: Train Loss = 0.0195, Val Loss = 0.0324\n",
      "Epoch 23/50: Train Loss = 0.0190, Val Loss = 0.0356\n",
      "Epoch 24/50: Train Loss = 0.0193, Val Loss = 0.0332\n",
      "Epoch 25/50: Train Loss = 0.0193, Val Loss = 0.0360\n",
      "Epoch 26/50: Train Loss = 0.0193, Val Loss = 0.0369\n",
      "Epoch 27/50: Train Loss = 0.0190, Val Loss = 0.0374\n",
      "Epoch 28/50: Train Loss = 0.0192, Val Loss = 0.0384\n",
      "Epoch 29/50: Train Loss = 0.0189, Val Loss = 0.0401\n",
      "Epoch 30/50: Train Loss = 0.0187, Val Loss = 0.0380\n",
      "Epoch 31/50: Train Loss = 0.0185, Val Loss = 0.0360\n",
      "Epoch 32/50: Train Loss = 0.0188, Val Loss = 0.0401\n",
      "Epoch 33/50: Train Loss = 0.0192, Val Loss = 0.0374\n",
      "Epoch 34/50: Train Loss = 0.0190, Val Loss = 0.0390\n",
      "Epoch 35/50: Train Loss = 0.0190, Val Loss = 0.0411\n",
      "Epoch 36/50: Train Loss = 0.0191, Val Loss = 0.0394\n",
      "Epoch 37/50: Train Loss = 0.0186, Val Loss = 0.0442\n",
      "Epoch 38/50: Train Loss = 0.0191, Val Loss = 0.0418\n",
      "Epoch 39/50: Train Loss = 0.0186, Val Loss = 0.0415\n",
      "Epoch 40/50: Train Loss = 0.0195, Val Loss = 0.0424\n",
      "Epoch 41/50: Train Loss = 0.0189, Val Loss = 0.0435\n",
      "Epoch 42/50: Train Loss = 0.0187, Val Loss = 0.0476\n",
      "Epoch 43/50: Train Loss = 0.0189, Val Loss = 0.0402\n",
      "Epoch 44/50: Train Loss = 0.0184, Val Loss = 0.0445\n",
      "Epoch 45/50: Train Loss = 0.0190, Val Loss = 0.0425\n",
      "Epoch 46/50: Train Loss = 0.0186, Val Loss = 0.0481\n",
      "Epoch 47/50: Train Loss = 0.0184, Val Loss = 0.0415\n",
      "Epoch 48/50: Train Loss = 0.0186, Val Loss = 0.0444\n",
      "Epoch 49/50: Train Loss = 0.0185, Val Loss = 0.0501\n",
      "Epoch 50/50: Train Loss = 0.0184, Val Loss = 0.0486\n",
      "Metrics: {'F1 Score': 0.992568983900801, 'Accuracy': 0.9925654809561936, 'Precision': 0.9925978469023191, 'Recall': 0.9925654809561936}\n",
      "\n",
      "--- Learning Rate: 0.01 ---\n",
      "Epoch 1/50: Train Loss = 0.0433, Val Loss = 0.0270\n",
      "Epoch 2/50: Train Loss = 0.0299, Val Loss = 0.0286\n",
      "Epoch 3/50: Train Loss = 0.0271, Val Loss = 0.0297\n",
      "Epoch 4/50: Train Loss = 0.0267, Val Loss = 0.0296\n",
      "Epoch 5/50: Train Loss = 0.0249, Val Loss = 0.0358\n",
      "Epoch 6/50: Train Loss = 0.0255, Val Loss = 0.0308\n",
      "Epoch 7/50: Train Loss = 0.0247, Val Loss = 0.0294\n",
      "Epoch 8/50: Train Loss = 0.0253, Val Loss = 0.0276\n",
      "Epoch 9/50: Train Loss = 0.0244, Val Loss = 0.0293\n",
      "Epoch 10/50: Train Loss = 0.0241, Val Loss = 0.0321\n",
      "Epoch 11/50: Train Loss = 0.0240, Val Loss = 0.0284\n",
      "Epoch 12/50: Train Loss = 0.0233, Val Loss = 0.0375\n",
      "Epoch 13/50: Train Loss = 0.0243, Val Loss = 0.0344\n",
      "Epoch 14/50: Train Loss = 0.0240, Val Loss = 0.0340\n",
      "Epoch 15/50: Train Loss = 0.0243, Val Loss = 0.0406\n",
      "Epoch 16/50: Train Loss = 0.0230, Val Loss = 0.0405\n",
      "Epoch 17/50: Train Loss = 0.0232, Val Loss = 0.0377\n",
      "Epoch 18/50: Train Loss = 0.0226, Val Loss = 0.0365\n",
      "Epoch 19/50: Train Loss = 0.0238, Val Loss = 0.0389\n",
      "Epoch 20/50: Train Loss = 0.0218, Val Loss = 0.0393\n",
      "Epoch 21/50: Train Loss = 0.0232, Val Loss = 0.0458\n",
      "Epoch 22/50: Train Loss = 0.0233, Val Loss = 0.0478\n",
      "Epoch 23/50: Train Loss = 0.0221, Val Loss = 0.0452\n",
      "Epoch 24/50: Train Loss = 0.0226, Val Loss = 0.0418\n",
      "Epoch 25/50: Train Loss = 0.0243, Val Loss = 0.0666\n",
      "Epoch 26/50: Train Loss = 0.0230, Val Loss = 0.0592\n",
      "Epoch 27/50: Train Loss = 0.0232, Val Loss = 0.0631\n",
      "Epoch 28/50: Train Loss = 0.0214, Val Loss = 0.0550\n",
      "Epoch 29/50: Train Loss = 0.0216, Val Loss = 0.0556\n",
      "Epoch 30/50: Train Loss = 0.0225, Val Loss = 0.0515\n",
      "Epoch 31/50: Train Loss = 0.0213, Val Loss = 0.0568\n",
      "Epoch 32/50: Train Loss = 0.0231, Val Loss = 0.0588\n",
      "Epoch 33/50: Train Loss = 0.0222, Val Loss = 0.0573\n",
      "Epoch 34/50: Train Loss = 0.0216, Val Loss = 0.0723\n",
      "Epoch 35/50: Train Loss = 0.0254, Val Loss = 0.0677\n",
      "Epoch 36/50: Train Loss = 0.0234, Val Loss = 0.0592\n",
      "Epoch 37/50: Train Loss = 0.0233, Val Loss = 0.0709\n",
      "Epoch 38/50: Train Loss = 0.0222, Val Loss = 0.0706\n",
      "Epoch 39/50: Train Loss = 0.0227, Val Loss = 0.0660\n",
      "Epoch 40/50: Train Loss = 0.0222, Val Loss = 0.0561\n",
      "Epoch 41/50: Train Loss = 0.0215, Val Loss = 0.0697\n",
      "Epoch 42/50: Train Loss = 0.0240, Val Loss = 0.0592\n",
      "Epoch 43/50: Train Loss = 0.0217, Val Loss = 0.0618\n",
      "Epoch 44/50: Train Loss = 0.0216, Val Loss = 0.0536\n",
      "Epoch 45/50: Train Loss = 0.0220, Val Loss = 0.0576\n",
      "Epoch 46/50: Train Loss = 0.0213, Val Loss = 0.0592\n",
      "Epoch 47/50: Train Loss = 0.0224, Val Loss = 0.0661\n",
      "Epoch 48/50: Train Loss = 0.0228, Val Loss = 0.0599\n",
      "Epoch 49/50: Train Loss = 0.0245, Val Loss = 0.0571\n",
      "Epoch 50/50: Train Loss = 0.0223, Val Loss = 0.0591\n",
      "Metrics: {'F1 Score': 0.9929130943912803, 'Accuracy': 0.9929086126043692, 'Precision': 0.9929641137690816, 'Recall': 0.9929086126043692}\n",
      "\n",
      "--- Learning Rate: 0.02 ---\n",
      "Epoch 1/50: Train Loss = 0.0459, Val Loss = 0.0341\n",
      "Epoch 2/50: Train Loss = 0.0378, Val Loss = 0.0304\n",
      "Epoch 3/50: Train Loss = 0.0358, Val Loss = 0.0295\n",
      "Epoch 4/50: Train Loss = 0.0347, Val Loss = 0.0340\n",
      "Epoch 5/50: Train Loss = 0.0319, Val Loss = 0.0356\n",
      "Epoch 6/50: Train Loss = 0.0328, Val Loss = 0.0399\n",
      "Epoch 7/50: Train Loss = 0.0340, Val Loss = 0.0328\n",
      "Epoch 8/50: Train Loss = 0.0318, Val Loss = 0.0410\n",
      "Epoch 9/50: Train Loss = 0.0305, Val Loss = 0.0388\n",
      "Epoch 10/50: Train Loss = 0.0307, Val Loss = 0.0395\n",
      "Epoch 11/50: Train Loss = 0.0315, Val Loss = 0.0457\n",
      "Epoch 12/50: Train Loss = 0.0373, Val Loss = 0.0313\n",
      "Epoch 13/50: Train Loss = 0.0319, Val Loss = 0.0473\n",
      "Epoch 14/50: Train Loss = 0.0297, Val Loss = 0.0401\n",
      "Epoch 15/50: Train Loss = 0.0310, Val Loss = 0.0582\n",
      "Epoch 16/50: Train Loss = 0.0278, Val Loss = 0.0569\n",
      "Epoch 17/50: Train Loss = 0.0307, Val Loss = 0.0454\n",
      "Epoch 18/50: Train Loss = 0.0292, Val Loss = 0.0647\n",
      "Epoch 19/50: Train Loss = 0.0320, Val Loss = 0.0532\n",
      "Epoch 20/50: Train Loss = 0.0299, Val Loss = 0.0547\n",
      "Epoch 21/50: Train Loss = 0.0354, Val Loss = 0.0627\n",
      "Epoch 22/50: Train Loss = 0.0373, Val Loss = 0.0659\n",
      "Epoch 23/50: Train Loss = 0.0291, Val Loss = 0.0709\n",
      "Epoch 24/50: Train Loss = 0.0291, Val Loss = 0.0646\n",
      "Epoch 25/50: Train Loss = 0.0291, Val Loss = 0.0567\n",
      "Epoch 26/50: Train Loss = 0.0309, Val Loss = 0.0670\n",
      "Epoch 27/50: Train Loss = 0.0291, Val Loss = 0.0587\n",
      "Epoch 28/50: Train Loss = 0.0299, Val Loss = 0.0815\n",
      "Epoch 29/50: Train Loss = 0.0288, Val Loss = 0.0788\n",
      "Epoch 30/50: Train Loss = 0.0304, Val Loss = 0.0500\n",
      "Epoch 31/50: Train Loss = 0.0345, Val Loss = 0.0633\n",
      "Epoch 32/50: Train Loss = 0.0388, Val Loss = 0.0566\n",
      "Epoch 33/50: Train Loss = 0.0357, Val Loss = 0.0726\n",
      "Epoch 34/50: Train Loss = 0.0284, Val Loss = 0.0683\n",
      "Epoch 35/50: Train Loss = 0.0300, Val Loss = 0.0748\n",
      "Epoch 36/50: Train Loss = 0.0333, Val Loss = 0.0501\n",
      "Epoch 37/50: Train Loss = 0.0281, Val Loss = 0.0767\n",
      "Epoch 38/50: Train Loss = 0.0349, Val Loss = 0.0546\n",
      "Epoch 39/50: Train Loss = 0.0294, Val Loss = 0.0768\n",
      "Epoch 40/50: Train Loss = 0.0270, Val Loss = 0.1108\n",
      "Epoch 41/50: Train Loss = 0.0271, Val Loss = 0.0755\n",
      "Epoch 42/50: Train Loss = 0.0282, Val Loss = 0.0688\n",
      "Epoch 43/50: Train Loss = 0.0273, Val Loss = 0.1051\n",
      "Epoch 44/50: Train Loss = 0.0303, Val Loss = 0.1001\n",
      "Epoch 45/50: Train Loss = 0.0315, Val Loss = 0.1105\n",
      "Epoch 46/50: Train Loss = 0.0325, Val Loss = 0.0849\n",
      "Epoch 47/50: Train Loss = 0.0315, Val Loss = 0.0903\n",
      "Epoch 48/50: Train Loss = 0.0336, Val Loss = 0.1308\n",
      "Epoch 49/50: Train Loss = 0.0277, Val Loss = 0.1112\n",
      "Epoch 50/50: Train Loss = 0.0262, Val Loss = 0.1156\n",
      "Metrics: {'F1 Score': 0.9927997198505774, 'Accuracy': 0.9927942353883107, 'Precision': 0.9928737802530572, 'Recall': 0.9927942353883107}\n",
      "\n",
      "--- Learning Rate: 0.05 ---\n",
      "Epoch 1/50: Train Loss = 0.0781, Val Loss = 0.0590\n",
      "Epoch 2/50: Train Loss = 0.0779, Val Loss = 0.0367\n",
      "Epoch 3/50: Train Loss = 0.0873, Val Loss = 0.0581\n",
      "Epoch 4/50: Train Loss = 0.0636, Val Loss = 0.0461\n",
      "Epoch 5/50: Train Loss = 0.0856, Val Loss = 0.0497\n",
      "Epoch 6/50: Train Loss = 0.0740, Val Loss = 0.0449\n",
      "Epoch 7/50: Train Loss = 0.0734, Val Loss = 0.0557\n",
      "Epoch 8/50: Train Loss = 0.0618, Val Loss = 0.0481\n",
      "Epoch 9/50: Train Loss = 0.0718, Val Loss = 0.0448\n",
      "Epoch 10/50: Train Loss = 0.0789, Val Loss = 0.0482\n",
      "Epoch 11/50: Train Loss = 0.0615, Val Loss = 0.0476\n",
      "Epoch 12/50: Train Loss = 0.0782, Val Loss = 0.0576\n",
      "Epoch 13/50: Train Loss = 0.0808, Val Loss = 0.0535\n",
      "Epoch 14/50: Train Loss = 0.0653, Val Loss = 0.0437\n",
      "Epoch 15/50: Train Loss = 0.0720, Val Loss = 0.0652\n",
      "Epoch 16/50: Train Loss = 0.0574, Val Loss = 0.0911\n",
      "Epoch 17/50: Train Loss = 0.0681, Val Loss = 0.0358\n",
      "Epoch 18/50: Train Loss = 0.0651, Val Loss = 0.0591\n",
      "Epoch 19/50: Train Loss = 0.0621, Val Loss = 0.0738\n",
      "Epoch 20/50: Train Loss = 0.0722, Val Loss = 0.0390\n",
      "Epoch 21/50: Train Loss = 0.0979, Val Loss = 0.1297\n",
      "Epoch 22/50: Train Loss = 0.0961, Val Loss = 0.1724\n",
      "Epoch 23/50: Train Loss = 0.0718, Val Loss = 0.0800\n",
      "Epoch 24/50: Train Loss = 0.0569, Val Loss = 0.0560\n",
      "Epoch 25/50: Train Loss = 0.0706, Val Loss = 0.0492\n",
      "Epoch 26/50: Train Loss = 0.0479, Val Loss = 0.1264\n",
      "Epoch 27/50: Train Loss = 0.0692, Val Loss = 0.2523\n",
      "Epoch 28/50: Train Loss = 0.0662, Val Loss = 0.0642\n",
      "Epoch 29/50: Train Loss = 0.0465, Val Loss = 0.1077\n",
      "Epoch 30/50: Train Loss = 0.0775, Val Loss = 0.1397\n",
      "Epoch 31/50: Train Loss = 0.0808, Val Loss = 0.0430\n",
      "Epoch 32/50: Train Loss = 0.0571, Val Loss = 0.1435\n",
      "Epoch 33/50: Train Loss = 0.0552, Val Loss = 0.0720\n",
      "Epoch 34/50: Train Loss = 0.0536, Val Loss = 0.0399\n",
      "Epoch 35/50: Train Loss = 0.0454, Val Loss = 0.0738\n",
      "Epoch 36/50: Train Loss = 0.0935, Val Loss = 0.0595\n",
      "Epoch 37/50: Train Loss = 0.0482, Val Loss = 0.0643\n",
      "Epoch 38/50: Train Loss = 0.0709, Val Loss = 0.1180\n",
      "Epoch 39/50: Train Loss = 0.0582, Val Loss = 0.0657\n",
      "Epoch 40/50: Train Loss = 0.0778, Val Loss = 0.2051\n",
      "Epoch 41/50: Train Loss = 0.0528, Val Loss = 0.1869\n",
      "Epoch 42/50: Train Loss = 0.0777, Val Loss = 0.0410\n",
      "Epoch 43/50: Train Loss = 0.0639, Val Loss = 0.0959\n",
      "Epoch 44/50: Train Loss = 0.0648, Val Loss = 0.0446\n",
      "Epoch 45/50: Train Loss = 0.0430, Val Loss = 0.2360\n",
      "Epoch 46/50: Train Loss = 0.0540, Val Loss = 0.1444\n",
      "Epoch 47/50: Train Loss = 0.0634, Val Loss = 0.0730\n",
      "Epoch 48/50: Train Loss = 0.0803, Val Loss = 0.0945\n",
      "Epoch 49/50: Train Loss = 0.0628, Val Loss = 0.2511\n",
      "Epoch 50/50: Train Loss = 0.1177, Val Loss = 0.1696\n",
      "Metrics: {'F1 Score': 0.9901749899963066, 'Accuracy': 0.9901635594189637, 'Precision': 0.9903544299893332, 'Recall': 0.9901635594189637}\n",
      "\n",
      "--- Comprehensive Results ---\n",
      "\n",
      "Learning Rate: 0.001\n",
      "F1 Score: 0.9926834152594892\n",
      "Accuracy: 0.9926798581722521\n",
      "Precision: 0.9927139965667622\n",
      "Recall: 0.9926798581722521\n",
      "\n",
      "Learning Rate: 0.002\n",
      "F1 Score: 0.992568983900801\n",
      "Accuracy: 0.9925654809561936\n",
      "Precision: 0.9925978469023191\n",
      "Recall: 0.9925654809561936\n",
      "\n",
      "Learning Rate: 0.01\n",
      "F1 Score: 0.9929130943912803\n",
      "Accuracy: 0.9929086126043692\n",
      "Precision: 0.9929641137690816\n",
      "Recall: 0.9929086126043692\n",
      "\n",
      "Learning Rate: 0.02\n",
      "F1 Score: 0.9927997198505774\n",
      "Accuracy: 0.9927942353883107\n",
      "Precision: 0.9928737802530572\n",
      "Recall: 0.9927942353883107\n",
      "\n",
      "Learning Rate: 0.05\n",
      "F1 Score: 0.9901749899963066\n",
      "Accuracy: 0.9901635594189637\n",
      "Precision: 0.9903544299893332\n",
      "Recall: 0.9901635594189637\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
