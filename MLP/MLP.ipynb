{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XSSDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, optimizer, criterion, epochs):\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_epoch_loss = 0\n",
    "        for features, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_epoch_loss += loss.item()\n",
    "        \n",
    "        train_epoch_loss /= len(train_loader)\n",
    "        train_losses.append(train_epoch_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        val_epoch_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_epoch_loss += loss.item()\n",
    "            \n",
    "            val_epoch_loss /= len(val_loader)\n",
    "            val_losses.append(val_epoch_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}: Train Loss = {train_epoch_loss:.4f}, Val Loss = {val_epoch_loss:.4f}')\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "def evaluate_metrics(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            outputs = model(features)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'F1 Score': f1,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load dataset\n",
    "    dataset_path = '../Training Dataset/final_dataset.csv'\n",
    "    \n",
    "    # Read CSV and handle NaN values\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    \n",
    "    # Remove rows with NaN values in 'Sentence' or 'Label' columns\n",
    "    df = df.dropna(subset=['Sentence', 'Label'])\n",
    "    \n",
    "    # Convert 'Sentence' to string type and replace any remaining NaNs\n",
    "    df['Sentence'] = df['Sentence'].astype(str).fillna('')\n",
    "    \n",
    "    # Print dataset info\n",
    "    print(\"Dataset shape after cleaning:\", df.shape)\n",
    "    print(\"\\nSample of cleaned dataset:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Text Vectorization\n",
    "    vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    X = vectorizer.fit_transform(df['Sentence']).toarray()\n",
    "    y = df['Label'].values\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.33, random_state=42)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataset = XSSDataset(X_train, y_train)\n",
    "    val_dataset = XSSDataset(X_val, y_val)\n",
    "    test_dataset = XSSDataset(X_test, y_test)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "    \n",
    "    # Print first 3 samples\n",
    "    print(\"\\nFirst 3 Training Samples:\")\n",
    "    for i, (features, label) in enumerate(train_loader):\n",
    "        if i < 1:\n",
    "            print(\"Features shape:\", features[:3].shape)\n",
    "            print(\"Labels:\", label[:3])\n",
    "        break\n",
    "    \n",
    "    # Learning rates to experiment\n",
    "    learning_rates = [0.001, 0.002, 0.01, 0.02, 0.05]\n",
    "    epochs = 20\n",
    "    results = {}\n",
    "    \n",
    "    # Create a figure with 5 subplots, one for each learning rate\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    for lr in learning_rates:\n",
    "        print(f\"\\n--- Learning Rate: {lr} ---\")\n",
    "        \n",
    "        # Reset model and optimizer for each learning rate\n",
    "        model = MLPModel(X_train.shape[1])\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        train_losses, val_losses = train_and_evaluate(\n",
    "            model, train_loader, val_loader, optimizer, criterion, epochs\n",
    "        )\n",
    "        \n",
    "        # Plot losses for this learning rate in a separate subplot\n",
    "        plt.subplot(2, 3, learning_rates.index(lr) + 1)\n",
    "        plt.plot(range(1, epochs + 1), train_losses, label='Train Loss', marker='o')\n",
    "        plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss', marker='o')\n",
    "        plt.title(f'Loss Curves - Learning Rate: {lr}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.xticks(range(1, epochs + 1))\n",
    "        \n",
    "        # Evaluate metrics\n",
    "        metrics = evaluate_metrics(model, test_loader)\n",
    "        results[lr] = metrics\n",
    "        \n",
    "        print(\"Metrics:\", metrics)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('learning_rate_losses.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Print comprehensive results\n",
    "    print(\"\\n--- Comprehensive Results ---\")\n",
    "    for lr, metrics in results.items():\n",
    "        print(f\"\\nLearning Rate: {lr}\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after cleaning: (88309, 3)\n",
      "\n",
      "Sample of cleaned dataset:\n",
      "   Unnamed: 0                                           Sentence  Label\n",
      "0           0  form.search_text=Dell%22%3E%3Cscript%3Ealert(/...      1\n",
      "1           1         site=message&msg=<script>alert(1)</script>      1\n",
      "2           2  Itemid=%22onmouseover=alert%28document.cookie%...      1\n",
      "3           3  uilang=en%22%3E%3Cscript%3Ealert%28document.co...      1\n",
      "4           4  msg=<ScRiPt>alert('LastRider-CyberBellona')</S...      1\n",
      "\n",
      "First 3 Training Samples:\n",
      "Features shape: torch.Size([3, 1000])\n",
      "Labels: tensor([1, 1, 1])\n",
      "\n",
      "--- Learning Rate: 0.001 ---\n",
      "Epoch 1/20: Train Loss = 0.0609, Val Loss = 0.0263\n",
      "Epoch 2/20: Train Loss = 0.0282, Val Loss = 0.0253\n",
      "Epoch 3/20: Train Loss = 0.0263, Val Loss = 0.0253\n",
      "Epoch 4/20: Train Loss = 0.0251, Val Loss = 0.0255\n",
      "Epoch 5/20: Train Loss = 0.0237, Val Loss = 0.0268\n",
      "Epoch 6/20: Train Loss = 0.0234, Val Loss = 0.0266\n",
      "Epoch 7/20: Train Loss = 0.0226, Val Loss = 0.0271\n",
      "Epoch 8/20: Train Loss = 0.0226, Val Loss = 0.0274\n",
      "Epoch 9/20: Train Loss = 0.0218, Val Loss = 0.0279\n",
      "Epoch 10/20: Train Loss = 0.0214, Val Loss = 0.0284\n",
      "Epoch 11/20: Train Loss = 0.0211, Val Loss = 0.0288\n",
      "Epoch 12/20: Train Loss = 0.0208, Val Loss = 0.0296\n",
      "Epoch 13/20: Train Loss = 0.0205, Val Loss = 0.0300\n",
      "Epoch 14/20: Train Loss = 0.0203, Val Loss = 0.0302\n",
      "Epoch 15/20: Train Loss = 0.0204, Val Loss = 0.0307\n",
      "Epoch 16/20: Train Loss = 0.0202, Val Loss = 0.0328\n",
      "Epoch 17/20: Train Loss = 0.0197, Val Loss = 0.0324\n",
      "Epoch 18/20: Train Loss = 0.0198, Val Loss = 0.0332\n",
      "Epoch 19/20: Train Loss = 0.0197, Val Loss = 0.0303\n",
      "Epoch 20/20: Train Loss = 0.0195, Val Loss = 0.0322\n",
      "Metrics: {'F1 Score': 0.9925694215626719, 'Accuracy': 0.9925654809561936, 'Precision': 0.9926056814470962, 'Recall': 0.9925654809561936}\n",
      "\n",
      "--- Learning Rate: 0.002 ---\n",
      "Epoch 1/20: Train Loss = 0.0514, Val Loss = 0.0254\n",
      "Epoch 2/20: Train Loss = 0.0277, Val Loss = 0.0257\n",
      "Epoch 3/20: Train Loss = 0.0254, Val Loss = 0.0246\n",
      "Epoch 4/20: Train Loss = 0.0241, Val Loss = 0.0256\n",
      "Epoch 5/20: Train Loss = 0.0234, Val Loss = 0.0259\n",
      "Epoch 6/20: Train Loss = 0.0228, Val Loss = 0.0251\n",
      "Epoch 7/20: Train Loss = 0.0223, Val Loss = 0.0259\n",
      "Epoch 8/20: Train Loss = 0.0221, Val Loss = 0.0264\n",
      "Epoch 9/20: Train Loss = 0.0214, Val Loss = 0.0270\n",
      "Epoch 10/20: Train Loss = 0.0208, Val Loss = 0.0300\n",
      "Epoch 11/20: Train Loss = 0.0209, Val Loss = 0.0275\n",
      "Epoch 12/20: Train Loss = 0.0207, Val Loss = 0.0289\n",
      "Epoch 13/20: Train Loss = 0.0202, Val Loss = 0.0301\n",
      "Epoch 14/20: Train Loss = 0.0206, Val Loss = 0.0289\n",
      "Epoch 15/20: Train Loss = 0.0201, Val Loss = 0.0314\n",
      "Epoch 16/20: Train Loss = 0.0201, Val Loss = 0.0312\n",
      "Epoch 17/20: Train Loss = 0.0199, Val Loss = 0.0319\n",
      "Epoch 18/20: Train Loss = 0.0197, Val Loss = 0.0311\n",
      "Epoch 19/20: Train Loss = 0.0202, Val Loss = 0.0312\n",
      "Epoch 20/20: Train Loss = 0.0195, Val Loss = 0.0341\n",
      "Metrics: {'F1 Score': 0.9927976305500071, 'Accuracy': 0.9927942353883107, 'Precision': 0.9928263918149859, 'Recall': 0.9927942353883107}\n",
      "\n",
      "--- Learning Rate: 0.01 ---\n",
      "Epoch 1/20: Train Loss = 0.0422, Val Loss = 0.0311\n",
      "Epoch 2/20: Train Loss = 0.0294, Val Loss = 0.0279\n",
      "Epoch 3/20: Train Loss = 0.0275, Val Loss = 0.0275\n",
      "Epoch 4/20: Train Loss = 0.0268, Val Loss = 0.0278\n",
      "Epoch 5/20: Train Loss = 0.0256, Val Loss = 0.0303\n",
      "Epoch 6/20: Train Loss = 0.0266, Val Loss = 0.0284\n",
      "Epoch 7/20: Train Loss = 0.0260, Val Loss = 0.0274\n",
      "Epoch 8/20: Train Loss = 0.0247, Val Loss = 0.0330\n",
      "Epoch 9/20: Train Loss = 0.0248, Val Loss = 0.0296\n",
      "Epoch 10/20: Train Loss = 0.0241, Val Loss = 0.0395\n",
      "Epoch 11/20: Train Loss = 0.0241, Val Loss = 0.0413\n",
      "Epoch 12/20: Train Loss = 0.0243, Val Loss = 0.0335\n",
      "Epoch 13/20: Train Loss = 0.0235, Val Loss = 0.0358\n",
      "Epoch 14/20: Train Loss = 0.0233, Val Loss = 0.0331\n",
      "Epoch 15/20: Train Loss = 0.0232, Val Loss = 0.0451\n",
      "Epoch 16/20: Train Loss = 0.0239, Val Loss = 0.0364\n",
      "Epoch 17/20: Train Loss = 0.0229, Val Loss = 0.0415\n",
      "Epoch 18/20: Train Loss = 0.0237, Val Loss = 0.0434\n",
      "Epoch 19/20: Train Loss = 0.0227, Val Loss = 0.0404\n",
      "Epoch 20/20: Train Loss = 0.0228, Val Loss = 0.0493\n",
      "Metrics: {'F1 Score': 0.993027298268014, 'Accuracy': 0.9930229898204278, 'Precision': 0.9930759624393557, 'Recall': 0.9930229898204278}\n",
      "\n",
      "--- Learning Rate: 0.02 ---\n",
      "Epoch 1/20: Train Loss = 0.0455, Val Loss = 0.0316\n",
      "Epoch 2/20: Train Loss = 0.0368, Val Loss = 0.0311\n",
      "Epoch 3/20: Train Loss = 0.0343, Val Loss = 0.0315\n",
      "Epoch 4/20: Train Loss = 0.0357, Val Loss = 0.0340\n",
      "Epoch 5/20: Train Loss = 0.0311, Val Loss = 0.0331\n",
      "Epoch 6/20: Train Loss = 0.0313, Val Loss = 0.0392\n",
      "Epoch 7/20: Train Loss = 0.0369, Val Loss = 0.0366\n",
      "Epoch 8/20: Train Loss = 0.0325, Val Loss = 0.0349\n",
      "Epoch 9/20: Train Loss = 0.0296, Val Loss = 0.0332\n",
      "Epoch 10/20: Train Loss = 0.0317, Val Loss = 0.0340\n",
      "Epoch 11/20: Train Loss = 0.0347, Val Loss = 0.0383\n",
      "Epoch 12/20: Train Loss = 0.0304, Val Loss = 0.0468\n",
      "Epoch 13/20: Train Loss = 0.0311, Val Loss = 0.0451\n",
      "Epoch 14/20: Train Loss = 0.0281, Val Loss = 0.0372\n",
      "Epoch 15/20: Train Loss = 0.0311, Val Loss = 0.0386\n",
      "Epoch 16/20: Train Loss = 0.0277, Val Loss = 0.0378\n",
      "Epoch 17/20: Train Loss = 0.0309, Val Loss = 0.0391\n",
      "Epoch 18/20: Train Loss = 0.0300, Val Loss = 0.0471\n",
      "Epoch 19/20: Train Loss = 0.0283, Val Loss = 0.0523\n",
      "Epoch 20/20: Train Loss = 0.0271, Val Loss = 0.0436\n",
      "Metrics: {'F1 Score': 0.9924573836142984, 'Accuracy': 0.992451103740135, 'Precision': 0.9925462921409444, 'Recall': 0.992451103740135}\n",
      "\n",
      "--- Learning Rate: 0.05 ---\n",
      "Epoch 1/20: Train Loss = 0.0761, Val Loss = 0.0416\n",
      "Epoch 2/20: Train Loss = 0.0687, Val Loss = 0.0417\n",
      "Epoch 3/20: Train Loss = 0.0733, Val Loss = 0.0448\n",
      "Epoch 4/20: Train Loss = 0.0759, Val Loss = 0.0376\n",
      "Epoch 5/20: Train Loss = 0.0765, Val Loss = 0.0367\n",
      "Epoch 6/20: Train Loss = 0.0694, Val Loss = 0.0414\n",
      "Epoch 7/20: Train Loss = 0.0703, Val Loss = 0.0713\n",
      "Epoch 8/20: Train Loss = 0.0584, Val Loss = 0.0365\n",
      "Epoch 9/20: Train Loss = 0.0735, Val Loss = 0.0364\n",
      "Epoch 10/20: Train Loss = 0.0646, Val Loss = 0.0532\n",
      "Epoch 11/20: Train Loss = 0.0833, Val Loss = 0.0394\n",
      "Epoch 12/20: Train Loss = 0.0507, Val Loss = 0.0380\n",
      "Epoch 13/20: Train Loss = 0.0534, Val Loss = 0.0429\n",
      "Epoch 14/20: Train Loss = 0.0773, Val Loss = 0.0429\n",
      "Epoch 15/20: Train Loss = 0.0699, Val Loss = 0.0528\n",
      "Epoch 16/20: Train Loss = 0.0620, Val Loss = 0.0659\n",
      "Epoch 17/20: Train Loss = 0.0709, Val Loss = 0.0359\n",
      "Epoch 18/20: Train Loss = 0.0655, Val Loss = 0.0450\n",
      "Epoch 19/20: Train Loss = 0.0599, Val Loss = 0.0645\n",
      "Epoch 20/20: Train Loss = 0.0494, Val Loss = 0.0458\n",
      "Metrics: {'F1 Score': 0.9912021145490193, 'Accuracy': 0.9911929543634908, 'Precision': 0.9913438141193794, 'Recall': 0.9911929543634908}\n",
      "\n",
      "--- Comprehensive Results ---\n",
      "\n",
      "Learning Rate: 0.001\n",
      "F1 Score: 0.9925694215626719\n",
      "Accuracy: 0.9925654809561936\n",
      "Precision: 0.9926056814470962\n",
      "Recall: 0.9925654809561936\n",
      "\n",
      "Learning Rate: 0.002\n",
      "F1 Score: 0.9927976305500071\n",
      "Accuracy: 0.9927942353883107\n",
      "Precision: 0.9928263918149859\n",
      "Recall: 0.9927942353883107\n",
      "\n",
      "Learning Rate: 0.01\n",
      "F1 Score: 0.993027298268014\n",
      "Accuracy: 0.9930229898204278\n",
      "Precision: 0.9930759624393557\n",
      "Recall: 0.9930229898204278\n",
      "\n",
      "Learning Rate: 0.02\n",
      "F1 Score: 0.9924573836142984\n",
      "Accuracy: 0.992451103740135\n",
      "Precision: 0.9925462921409444\n",
      "Recall: 0.992451103740135\n",
      "\n",
      "Learning Rate: 0.05\n",
      "F1 Score: 0.9912021145490193\n",
      "Accuracy: 0.9911929543634908\n",
      "Precision: 0.9913438141193794\n",
      "Recall: 0.9911929543634908\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
