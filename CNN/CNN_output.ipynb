{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T15:03:41.813528Z",
     "iopub.status.busy": "2024-11-04T15:03:41.813263Z",
     "iopub.status.idle": "2024-11-04T15:03:44.042501Z",
     "shell.execute_reply": "2024-11-04T15:03:44.042069Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T15:03:44.044677Z",
     "iopub.status.busy": "2024-11-04T15:03:44.044237Z",
     "iopub.status.idle": "2024-11-04T15:03:44.069720Z",
     "shell.execute_reply": "2024-11-04T15:03:44.069256Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "def load_dataset():\n",
    "    df = pd.read_csv('dataset/XSS_dataset.csv', encoding='utf-8-sig')\n",
    "    df = df[df.columns[-2:]]  # Only get sentence and labels\n",
    "\n",
    "    # Get Sentences data from data frame\n",
    "    sentences = df['Sentence'].values\n",
    "    labels = df['Label'].values\n",
    "\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T15:03:44.075199Z",
     "iopub.status.busy": "2024-11-04T15:03:44.075006Z",
     "iopub.status.idle": "2024-11-04T15:03:44.079030Z",
     "shell.execute_reply": "2024-11-04T15:03:44.078624Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to ASCII\n",
    "def convert_to_ascii(sentence):\n",
    "    sentence_ascii = []\n",
    "    for char in sentence:\n",
    "        if ord(char) < 8222:\n",
    "            if ord(char) == 8217:  # '\n",
    "                sentence_ascii.append(134)\n",
    "            elif ord(char) == 8221:  # \"\n",
    "                sentence_ascii.append(129)\n",
    "            elif ord(char) == 8220:  # \"\n",
    "                sentence_ascii.append(130)\n",
    "            elif ord(char) == 8216:  # '\n",
    "                sentence_ascii.append(131)\n",
    "            elif ord(char) == 8211:  # â€“\n",
    "                sentence_ascii.append(133)\n",
    "            if ord(char) <= 128:\n",
    "                sentence_ascii.append(ord(char))\n",
    "    zer = np.zeros((10000,))\n",
    "    for i in range(len(sentence_ascii)):\n",
    "        zer[i] = sentence_ascii[i]\n",
    "    zer.shape = (100, 100)\n",
    "    return zer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T15:03:44.080541Z",
     "iopub.status.busy": "2024-11-04T15:03:44.080352Z",
     "iopub.status.idle": "2024-11-04T15:03:45.219363Z",
     "shell.execute_reply": "2024-11-04T15:03:45.218950Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "def prepare_data(sentences):\n",
    "    arr = np.zeros((len(sentences), 100, 100))\n",
    "    for i in range(len(sentences)):\n",
    "        image = convert_to_ascii(sentences[i])\n",
    "        x = np.asarray(image, dtype='float')\n",
    "        image = cv2.resize(x, dsize=(5, 5), interpolation=cv2.INTER_CUBIC)\n",
    "        image /= 128\n",
    "        arr[i] = image\n",
    "\n",
    "    # Reshape data for input to CNN\n",
    "    data = arr.reshape(arr.shape[0], 1, 100, 100)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T15:03:45.225388Z",
     "iopub.status.busy": "2024-11-04T15:03:45.225195Z",
     "iopub.status.idle": "2024-11-04T15:03:45.228356Z",
     "shell.execute_reply": "2024-11-04T15:03:45.227989Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create PyTorch Dataset\n",
    "class XSSDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T15:03:45.569824Z",
     "iopub.status.busy": "2024-11-04T15:03:45.569618Z",
     "iopub.status.idle": "2024-11-04T15:03:45.573996Z",
     "shell.execute_reply": "2024-11-04T15:03:45.573647Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define CNN Model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(256 * 12 * 12, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.ReLU()(self.conv1(x)))\n",
    "        x = self.pool(nn.ReLU()(self.conv2(x)))\n",
    "        x = self.pool(nn.ReLU()(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = nn.ReLU()(self.fc3(x))\n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T15:03:45.575546Z",
     "iopub.status.busy": "2024-11-04T15:03:45.575354Z",
     "iopub.status.idle": "2024-11-04T19:07:56.819959Z",
     "shell.execute_reply": "2024-11-04T19:07:56.819660Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(learning_rate=0.001, num_epochs=18):\n",
    "    # Load and prepare data\n",
    "    sentences, labels = load_dataset()\n",
    "    \n",
    "    # Prepare data\n",
    "    data = prepare_data(sentences)\n",
    "\n",
    "    # Split data: train 70%, verify 20%, test 10%\n",
    "    train_data, temp_data, train_labels, temp_labels = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "    verify_data, test_data, verify_labels, test_labels = train_test_split(temp_data, temp_labels, test_size=1/3, random_state=42)\n",
    "\n",
    "    # Create datasets and loaders\n",
    "    train_dataset = XSSDataset(train_data, train_labels)\n",
    "    verify_dataset = XSSDataset(verify_data, verify_labels)\n",
    "    test_dataset = XSSDataset(test_data, test_labels)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    verify_loader = DataLoader(verify_dataset, batch_size=128, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    # Initialize model, loss, and optimizer\n",
    "    model = CNNModel()\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    loss_train = []\n",
    "    loss_verify = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.float())\n",
    "            loss = criterion(outputs.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        loss_train.append(epoch_loss / len(train_loader))\n",
    "\n",
    "        # Validation loss\n",
    "        model.eval()\n",
    "        verify_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in verify_loader:\n",
    "                outputs = model(inputs.float())\n",
    "                loss = criterion(outputs.squeeze(), labels.float())\n",
    "                verify_loss += loss.item()\n",
    "        loss_verify.append(verify_loss / len(verify_loader))\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss_train[-1]:.4f}, Verify Loss: {loss_verify[-1]:.4f}\")\n",
    "\n",
    "    # Save model weights\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    torch.save(model.state_dict(), 'models/xss_detection_model.pth')\n",
    "    print(\"Model weights saved to models/xss_detection_model.pth\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs.float())\n",
    "            preds = (outputs.squeeze() > 0.5).float()\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    print(\"\\nTest Set Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T19:07:56.821194Z",
     "iopub.status.busy": "2024-11-04T19:07:56.820978Z",
     "iopub.status.idle": "2024-11-04T19:07:57.167531Z",
     "shell.execute_reply": "2024-11-04T19:07:57.167248Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "    # Load the model\n",
    "    model = CNNModel()\n",
    "    model.load_state_dict(torch.load('models/xss_detection_model.pth'))\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare input\n",
    "    image = convert_to_ascii(input_sentence)\n",
    "    x = np.asarray(image, dtype='float')\n",
    "    image = cv2.resize(x, dsize=(100, 100), interpolation=cv2.INTER_CUBIC)\n",
    "    image /= 128\n",
    "    input_data = image.reshape(1, 1, 100, 100)\n",
    "    input_tensor = torch.tensor(input_data, dtype=torch.float32)\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        prediction = output.squeeze().item()\n",
    "\n",
    "    return prediction > 0.5, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T19:07:57.168933Z",
     "iopub.status.busy": "2024-11-04T19:07:57.168799Z",
     "iopub.status.idle": "2024-11-04T19:08:03.586070Z",
     "shell.execute_reply": "2024-11-04T19:08:03.585738Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='XSS Detection CNN')\n",
    "    parser.add_argument('--train', action='store_true', help='Train the model')\n",
    "    parser.add_argument('--predict', type=str, help='Predict XSS for a given sentence')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, help='Learning rate for training')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.train:\n",
    "        train_model(learning_rate=args.lr)\n",
    "    \n",
    "    if args.predict:\n",
    "        is_xss, confidence = predict(args.predict)\n",
    "        print(f\"Prediction: {'XSS' if is_xss else 'Not XSS'}\")\n",
    "        print(f\"Confidence: {confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-04T19:08:03.587488Z",
     "iopub.status.busy": "2024-11-04T19:08:03.587333Z",
     "iopub.status.idle": "2024-11-04T19:08:03.596289Z",
     "shell.execute_reply": "2024-11-04T19:08:03.596000Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--train] [--predict PREDICT] [--lr LR]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/home/is1ab/.local/share/jupyter/runtime/kernel-v2-1387757vHpZ6LXZXBno.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/is1ab/anaconda3/envs/myenv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
